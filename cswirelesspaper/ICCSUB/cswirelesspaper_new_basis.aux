\relax 
\bibstyle{IEEEtran}
\citation{akan2009cognitive}
\citation{Candes2006}
\citation{mishali2010theory}
\citation{tropp2010beyond}
\citation{Zhang2011b}
\citation{tian2006wavelet}
\citation{tian2006wavelet}
\citation{ling2014dlm}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\citation{mota2013d}
\@writefile{toc}{\contentsline {section}{\numberline {II}Signal Model}{2}}
\newlabel{basis}{{\unhbox \voidb@x \hbox {II-}.1}{2}}
\newlabel{basis-expansion}{{\unhbox \voidb@x \hbox {II-}.4}{2}}
\newlabel{def:a}{{II.1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Sensing Model}{2}}
\newlabel{sec:sensingmodel}{{III}{2}}
\newlabel{dist_system}{{\unhbox \voidb@x \hbox {III-}.9}{2}}
\newlabel{system}{{\unhbox \voidb@x \hbox {III-}.10}{2}}
\newlabel{opt}{{\unhbox \voidb@x \hbox {III-}.11}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Constrained Optimisation on Graphs}{2}}
\newlabel{sec:opt-on-graphs}{{IV}{2}}
\citation{Boyd2010a}
\citation{Boyd2010a}
\newlabel{barxc}{{\unhbox \voidb@x \hbox {IV-}.13}{3}}
\newlabel{constrainedbp}{{\unhbox \voidb@x \hbox {IV-}.14}{3}}
\newlabel{compact-constraints}{{\unhbox \voidb@x \hbox {IV-}.15}{3}}
\newlabel{constrainedbp1}{{\unhbox \voidb@x \hbox {IV-}.16}{3}}
\newlabel{aug-lagrange}{{\unhbox \voidb@x \hbox {IV-}.17}{3}}
\newlabel{generic-iterations}{{\unhbox \voidb@x \hbox {IV-}.21}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {IV.1}{\ignorespaces The algorithm at Node \(j\)}}{4}}
\newlabel{DADMM}{{IV.1}{4}}
\newlabel{dadmm_algo_lasso}{{\unhbox \voidb@x \hbox {IV-}.26}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results}{4}}
\newlabel{sec:results}{{V}{4}}
\citation{chen1998atomic}
\citation{bazerque2008}
\citation{bazerque2008}
\citation{DADMMconvergence}
\citation{nishihara2015general}
\citation{su2014differential}
\citation{mokhtari2015dqm}
\citation{ling2014dlm}
\citation{goldstein2014fast}
\bibdata{cswireless3}
\bibcite{akan2009cognitive}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {V.2}{\ignorespaces Left to right: (a) The original signal. (b) The gradient \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {def:a}\unskip \@@italiccorr )}} of the original signal. (c) Recovery using DADMM, 1000 iterations, \(\sigma ^2_n = 5\). (d) Recovery using DADMM, 1000 iterations, \(\sigma ^2_n = 20\) }}{5}}
\newlabel{different_sigs}{{V.2}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusions}{5}}
\bibcite{bazerque2008}{2}
\bibcite{Boyd2010a}{3}
\bibcite{Candes2006}{4}
\bibcite{goldstein2014fast}{5}
\bibcite{ling2014dlm}{6}
\bibcite{mishali2010theory}{7}
\bibcite{mokhtari2015dqm}{8}
\bibcite{mota2013d}{9}
\bibcite{nishihara2015general}{10}
\bibcite{DADMMconvergence}{11}
\bibcite{su2014differential}{12}
\bibcite{tian2006wavelet}{13}
\bibcite{tropp2010beyond}{14}
\bibcite{Zhang2011b}{15}
\@writefile{lof}{\contentsline {figure}{\numberline {V.3}{\ignorespaces MSE vs SNR for the sensing model showing the performance of distributed and centralised solvers. The performance of DADMM is consistently within \(10^{-2}\) of ADMM, and within the error bars of ADMM at low SNRs. The variance of estimates produced by DADMM is larger than ADMM, due to nodes performing computations on a subset of data. Both estimates are consistently within \(10^{-1}\) of the optimal solution, which is sufficient to classify occupied bands.}}{6}}
\newlabel{msevssnr0}{{V.3}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {V.4}{\ignorespaces The progress of the distributed solver as a function of the number of iterations, with different values of the regression parameter \( \lambda \). For a fixed \( \lambda \) there is a single unique optimal solution, with higher \( \lambda \) favouring sparser solutions. The convergence of DADMM is slowed by smaller \( \lambda \). This is intuitive: solutions with fewer non-zero components should be identified in fewer iterations.}}{6}}
\newlabel{fig:differentLambda}{{V.4}{6}}
\@writefile{toc}{\contentsline {section}{References}{6}}
